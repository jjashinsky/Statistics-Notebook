---
title: "Reading Comprehension"
output: 
  html_document:
    theme: cerulean
    code_folding: hide
---

<script type="text/javascript">
 function showhide(id) {
    var e = document.getElementById(id);
    e.style.display = (e.style.display == 'block') ? 'none' : 'block';
 }
</script>

```{r, include=FALSE}
library(mosaic)
library(car)
library(DT)
library(pander)
Baumann$Diff1 <- (Baumann$post.test.1 - Baumann$pretest.1)
Baumann$Diff2 <- (Baumann$post.test.2 - Baumann$pretest.2)
```

```{r, eval=FALSE}
#Play the above chunk and this one in your Console to access the data
View(Baumann)
?Baumann
```

### Background

"This study investigated the effectiveness of explicit instruction in 'think aloud' as a means to promote elementary students' comprehension monitoring abilities" [(Baumann & Jones, 1992)](http://jlr.sagepub.com/content/24/2/143.full.pdf).


<a href="javascript:showhide('abstract')">Details of the Study<span style="font-size:8pt;">&nbsp;(click to view)</span></a>

<div id="abstract" style="display:none;">

The following explanation of the experiment comes directly from the original research article [(Baumann & Jones, 1992)](http://jlr.sagepub.com/content/24/2/143.full.pdf).

<div style="padding-left:30px; padding-right:30px;">

Fourth-grade students from an elementary school in a rural midwestern community participated in the study. The school had adopted a team teaching plan, and three fourth-grade teachers shared an open classroom area. The teachers grouped the students for reading instruction across the three classes according to reading ability. One teacher each worked with a high [ability reading group], [one teacher worked with a] middle [ability group], and [the other teacher worked with the] low reading [ability] group. All groups used basal reading materials and were formed at the beginning of the school year on the basis of standardized achievement test data, prior performance in the basal reading program, and teacher judgment.

Sixty-eight of the 72 students in the fourth-grade team participated in the study; the four nonparticipating students were mainstreamed special education students for whom the instructional materials were considered to be too frustrating to read. The 68 students were assigned randomly to one of the three experimental groups (Strat = 23 students; DRTA = 23 students; Basal = 22 students). Because of illness and transfer to another school, incomplete data were obtained for one subject each from the Strat and DRTA groups. Thus, the final sample consisted of 66 students, 32 girls and 34 boys.

Posttests 1-3 were group-administered, quantitative measures obtained
for all students in the sample. Posttest 1 was an error detection test. Posttest 2 was a comprehension monitoring questionnaire. Posttest 3 was a modified cloze test. To statistically account for students'
preexperimental differences in comprehension monitoring abilities, two pretests were constructed, administered, and used as covariates in data analyses for Posttests 1-3.

Pretest 1. The first pretest involved an error detection task designed to evaluate students' preintervention ability to monitor their comprehension.... Students were provided the following directions which were printed on the pretest and read aloud by the experimenter: 'Read the story carefully. Try to understand it as you read. There will be 16 sentences that do not belong in the story. Look for them as you read. Ask yourself, "What does not make sense in this story?" Underline the 16 sentences that do not make sense. Check your work when you are finished. If you cannot read a
word, raise your hand, and we will help you.' Preceding Pretest 1, students were given a brief practice exercise that required them to identify obvious intruded sentences in two short texts. Pretest 1 was scored by calculating the number of correctly identified intruded sentences.

Pretest 2. The second pretest queried students about the strategies they believed to be useful in promoting their understanding of stories. In this pretest, modeled after an instrument developed by Schmitt (1988, 1990), the students were presented with 15 multiple-choice items like the following:

<div style="padding-left:15px;">
When I read, it is a good idea to:

A. sound out words I don't know.

B. make some guesses about what will happen in the story.

C. make a list of all the details in the story.

D. look up new words in the dictionary.

</div>

Posttest 1: Error detection test. Posttest 1 was the same in form as Pretest 1: with 16 intruded sentences lexically consistent at a local level but semantically inconsistent at a global level. 

Posttest 2: Comprehension monitoring questionnaire. Posttest 2, consisting of 18 items, was a slightly expanded version of Pretest 2. 

Posttest 3: Degrees of Reading Power. The Degrees of Reading Power (DRP)
(1986) is a standardized, commercially produced instrument that employs a modified cloze format (words are deleted from a selection and for each omission the student selects the most appropriate word from a list of five). According to the authors, DRP tests "are holistic measures of how well the messages within text are understood. . . . DRP tests focus measurement on determining how well students process or construct meaning from paragraphs as they read through a selection" (DRP Handbook, 1986, p. 1). Thus, the DRP, at one level, is a general reading comprehension assessment tool.

</div>

The data for this study are contained in the `Baumann` dataset.

</div>

<a href="javascript:showhide('long')">The Data <span style="font-size:8pt;">(click to view)</span></a>


<div id="long" style="display:none;">
```{r}
knitr::kable(Baumann)
```

</div>

From the details of the study we see that reading comprehension can be measured in many different ways, and in the case of this study we have three. Also, each experirmental teaching group may have a greater focus on a specific measuring type than another. 

For this reason the analysis will look at each type of test separately. This will provide each teaching group a fair chance to show improvement if it exists. Consequently alpha of 0.05 will also be split between the 3 analyses as well. 

## {.tabset .tabset-fade .tabset-pills}

### Type 1 Test

#### Hypothesis of Type 1 Tests 

This analysis will look at the difference of scores between each group. A Kruskal-Wallis test will be done on `Diff1` which was created by `post.test.1 - pretest.1`. 

Our null and alternative are written as thus,

$$
H_0: \text{= All samples represent a sample of data from the same distribution}
$$
$$
H_a: \text{= At least one distribution is stochastically different than the others}
$$

Level of significance will be defined as $\alpha$=0.017

----

#### Analysis of Type 1 Tests

The results of the Kruskal-Wallis tests are as follows, 

```{r}
pander(kruskal.test(Diff1 ~ group, data=Baumann))
```

The p-value of our test is smaller than the level of significance therefore we **reject the null hypothesis**. Indeed, there is a difference in distribution for at least one of the experimental groups. The significance of the test also leads us to believe that this represents the parent population.   

The boxplot and the statistical summary table shown below support these findings. 

```{r}
ggplot(data=Baumann, aes(x = group, fill = group)) +
  geom_boxplot(aes(y = Diff1)) +
  ggtitle("Results of Error Detection Tests ") +
  ylab("Difference in Scores Between pretest.1 and post.test.1") +
  xlab("Experimental Teaching Group") +
  theme(plot.title = element_text(hjust = .5))
```

```{r}
pander(favstats(Diff1 ~ group, data = Baumann))
```

#### Interpretation for Type 1 Tests 

The test and boxplot suggests that the experimental teaching group Basal preformed worse than their pre-test. It appears that the teaching style of this group did not prepare the students to detect errors. In fact the experiment seems to have hampered their ability. 

If it is the primary goal to have student detect errors and inconsistencies, which is potentially very useful skill in many professions, then this teaching style proves to be ineffective. The mean and medians of the other two groups, DRTA and Strat also do not appear to have any positive influence on the students, although this hasn't been proven statistically. This analysis suggests that other methods of teaching should be researched and implemented.   

----

### Type 2 Test 

#### Hypothesis of Type 2 Tests 

This analysis will look at the difference of scores between each group. A Kruskal-Wallis test will also be done on `Diff2` which was created by `post.test.2 - pretest.2`. 

Our null and alternative are written as thus,

$$
H_0: \text{= All samples represent a sample of data from the same distribution}
$$
$$
H_a: \text{= At least one distribution is stochastically different than the others}
$$

Level of significance will be defined as $\alpha$=0.017

----

#### Analysis of Type 2 Tests 


```{r}
pander(kruskal.test(Diff2 ~ group, data=Baumann))
```

Similarly to the type 1 test, the p-value leads us to **reject the null hypothesis**. One or more samples do in fact have a different distribution. 

We can see the distribution of the groups from the boxplot shown below. 
```{r}
ggplot(data=Baumann, aes(x = group, fill = group)) +
  geom_boxplot(aes(y = Diff2)) +
  ggtitle("Results of Comprehension Strategy Tests") +
  ylab("Difference in Scores between pretest.2 and post.test.2") +
  xlab("Experimental Teaching Group") +
  theme(plot.title = element_text(hjust = .5))
```

```{r}
pander(favstats(Diff2 ~ group, data = Baumann))
```


#### Interpretation of Type 2 Tests 

Unlike the first test results, the boxplot shows that the group Strat did improve in their scores. It also appears that the groups Basal and DRTA did not improve as much as Strat. Although the means and median of those two groups suggest that they made no improvement, the Kruskal-Wallis test only proved that the Strat group is different from the others. However, we can conclude that the Strat group on average will out preform the others.

Considering that the pre and post test 2 dealt with comprehension strategies, we see that the Strat teaching style better equipped students with the tools they need to read and understand material presented to them. The analysis suggests that the teaching involved with the Strat group is a potential candidate for an effective method of instruction.   

----

### Type 3 Test 

#### Hypothesis of Type 3 Tests 

Due to the fact that a pretest of the type 3 test was not delivered to the students we are unable to treat this as we did the two types of tests. Therefore this analysis will not look at which group improved the most, but rather which group preformed the best with the given test. The data `post.test.3` will be used in the Kruskal-Wallis test.   

Our null and alternative hypothesis will be similarly written as thus, 

$$
H_0: \text{= All samples represent a sample of data from the same distribution}
$$
$$
H_a: \text{= At least one distribution is stochastically different than the others}
$$

Level of significance will be defined as $\alpha$=0.016

----

#### Analysis of Type 3 Tests 

```{r}
pander(kruskal.test(post.test.3 ~ group, data=Baumann))
```

Just like the other two analyses we have a low p-value, therefore, the **null hypothesis is rejected** and we conclude the alternative.  

```{r}
ggplot(data=Baumann, aes(x = group, fill = group)) +
  geom_boxplot(aes(y = post.test.3)) +
  ggtitle("Results of DRP Test") +
  ylab("Scores of post.test.3") +
  xlab("Experimental Teaching Group") +
  theme(plot.title = element_text(hjust = .5))
```

This time it appears DRTA outperformed the rest. Therefore, we can conclude that this will be true for the entire population. 

```{r}
pander(favstats(post.test.3 ~ group, data = Baumann))
```

#### Interpretation of Type 3 Test

Although the Kruskal-Wallis test was successful in showing that DRTA is different from the other two, we are unable to show whether DRTA helped to improve their knowledge prior to being a part of the experiment. If another study was conducted and a pre-test was administered prior to any instruction or teaching, then there would be a good base line score to answer the same question as we did with type 1 and type 2. 

----

## Final Interpretation

The results of this analysis shows that certain groups performed better, and in one case worse, at specific tests of comprehension. The only clear result we got was that Strat performed better when it came to testing comprehension strategies, and the DRTA grouped preformed better when it came testing the student's ability to process and understand reading material. 

The suggestion can be made that researchers take a deeper look at the methods of each group. Take what worked the best from Strat and from DRTA and use it to create another method that could potentially work well in more than one key area of measuring comprehension. 

----

Source

Moore, D. S. and McCabe, G. P. (1993) Introduction to the Practice of Statistics, Second Edition. Freeman, p. 794–795.

References

Fox, J. (2008) Applied Regression Analysis and Generalized Linear Models, Second Edition. Sage.

Fox, J. and Weisberg, S. (2011) An R Companion to Applied Regression, Second Edition, Sage.

